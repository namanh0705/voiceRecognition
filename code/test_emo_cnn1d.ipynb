{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_emo_cnn1d.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSVJSCSJqvlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import soundfile\n",
        "import numpy as np\n",
        "import librosa\n",
        "import glob\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM_rf6arH-x2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81d74c2d-469e-48b4-efa2-7a76689a24be"
      },
      "source": [
        "import tensorflow as k\n",
        "print(k.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oejjMbAJrLv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "21b85651-4a2f-4176-86d2-5a4340970ba1"
      },
      "source": [
        "!pip install soundfile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDErr9Q_q8Zd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_feature(file_name, **kwargs):\n",
        "    mfcc = kwargs.get(\"mfcc\")\n",
        "    chroma = kwargs.get(\"chroma\")\n",
        "    mel = kwargs.get(\"mel\")\n",
        "    contrast = kwargs.get(\"contrast\")\n",
        "    tonnetz = kwargs.get(\"tonnetz\")\n",
        "    with soundfile.SoundFile(file_name) as sound_file:\n",
        "        X = sound_file.read(dtype=\"float32\")\n",
        "        sample_rate = sound_file.samplerate\n",
        "        if chroma or contrast:\n",
        "            stft = np.abs(librosa.stft(X))\n",
        "        result = np.array([])\n",
        "        if mfcc:\n",
        "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "            result = np.hstack((result, mfccs))\n",
        "        if chroma:\n",
        "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, chroma))\n",
        "        if mel:\n",
        "            mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, mel))\n",
        "        if contrast:\n",
        "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, contrast))\n",
        "        if tonnetz:\n",
        "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
        "            result = np.hstack((result, tonnetz))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcvloxf2q8_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pULpPPmkq_xZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "334b3875-8424-4e03-c03b-7aef1c38a12a"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "json_file= open('/content/drive/My Drive/speech_emotion/data/model.json','r')\n",
        "loaded_model_json= json_file.read()\n",
        "json_file.close()\n",
        "Loaded_Model = model_from_json(loaded_model_json)\n",
        "#Load weights into new model\n",
        "Loaded_Model.load_weights(\"/content/drive/My Drive/speech_emotion/data/model.h5\")\n",
        "print(\"Loaded\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssAFbU1mrpm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "em=['neutral','happy','angry']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qr2pBRdrDi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neu = 0\n",
        "hap = 0\n",
        "ang = 0 \n",
        "for file in glob.glob('/content/drive/My Drive/speech_emotion/neutral/*.wav'):\n",
        "  features = np.array(extract_feature(file, mfcc=True, chroma=True, mel=True).reshape(1, -1))\n",
        "    # predict\n",
        "  f=np.expand_dims(features,axis=2)\n",
        "  result = Loaded_Model.predict_classes(f)[0]\n",
        "    # show the result !\n",
        "\n",
        "  if (result == 0):\n",
        "    neu = neu+1\n",
        "  elif (result == 1):\n",
        "    hap = hap+1\n",
        "  else: ang = ang +1\n",
        "\n",
        "  print(\"result: \",em[result])\n",
        "\n",
        "print ('number neutral: ',neu)\n",
        "print ('number happy: ',hap)\n",
        "print ('number angry: ',ang)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}